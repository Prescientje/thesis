complex-modelbuilder5 early-stop TEST
This does not save any model files.
Sample length = 200
Learning rate = 0.001000
Stddev = 0.020000
Alpha = 0.002000
Superfactor = 25
Epochs = 50
Batch size = 8000
lmodelname = savedModels-complex/200-left/200-left
 
starting tensorflow section
 
 
Trial 1 savedModels-complex/200-left/200-left
 
00 -- 0.6733649696 -- 0.7159430480 -- 24.7606792450 -- 23.9730453491
01 -- 0.7949303806 -- 0.8207066268 -- 19.7666931152 -- 19.3014907837
02 -- 0.8422090730 -- 0.7173492705 -- 15.6319208145 -- 16.9429626465
03 -- 0.8521881774 -- 0.7205132712 -- 14.5524129868 -- 15.1644849777
04 -- 0.8715800574 -- 0.7931095096 -- 14.2468042374 -- 14.4723320007
05 -- 0.8570312653 -- 0.8189488487 -- 14.0871944427 -- 14.1980314255
06 -- 0.8672251841 -- 0.7818597293 -- 13.7701969147 -- 14.0494146347
07 -- 0.8884918078 -- 0.7969766216 -- 13.5529804230 -- 13.8106040955
08 -- 0.8992325268 -- 0.7901212867 -- 13.3574657440 -- 13.6301717758
09 -- 0.9089772883 -- 0.8057655124 -- 13.1739139557 -- 13.4510345459
10 -- 0.9130782901 -- 0.7885392863 -- 12.9927225113 -- 13.3144674301
11 -- 0.9218270940 -- 0.8073475127 -- 12.8102998734 -- 13.0935106277
12 -- 0.9246587381 -- 0.7938126208 -- 12.6301126480 -- 12.9624938965
13 -- 0.9328412131 -- 0.8017226226 -- 12.4457454681 -- 12.7570514679
14 -- 0.9358486144 -- 0.8089295131 -- 12.2669925690 -- 12.5721178055
15 -- 0.9374109009 -- 0.8163121814 -- 12.0898008347 -- 12.3833932877
16 -- 0.9423125745 -- 0.8075232906 -- 11.9071645737 -- 12.2316522598
17 -- 0.9461206476 -- 0.7982070663 -- 11.7307138443 -- 12.0888814926
18 -- 0.9485812487 -- 0.7990859554 -- 11.5524196625 -- 11.9207592010
19 -- 0.9481906771 -- 0.7945157321 -- 11.3822927475 -- 11.7666206360
20 -- 0.9521745074 -- 0.7973281772 -- 11.2049064636 -- 11.5874824524
21 -- 0.9544593513 -- 0.8106872913 -- 11.0303440094 -- 11.3927783966
22 -- 0.9540297225 -- 0.8182457374 -- 10.8619804382 -- 11.2043285370
23 -- 0.9563926807 -- 0.8133239585 -- 10.6908998489 -- 11.0562896729
24 -- 0.9606108540 -- 0.8029530673 -- 10.5219421387 -- 10.9252815247
25 -- 0.9615677544 -- 0.7945157321 -- 10.3599548340 -- 10.7979259491
26 -- 0.9581502529 -- 0.8207066268 -- 10.1999130249 -- 10.5658607483
27 -- 0.9642822270 -- 0.8140270698 -- 10.0322961807 -- 10.4364337921
28 -- 0.9429570176 -- 0.7533837230 -- 9.9126586914 -- 10.4644460678
29 -- 0.9652586560 -- 0.7881877307 -- 9.7228946686 -- 10.1844797134
30 -- 0.9647509130 -- 0.7987343997 -- 9.5657835007 -- 10.0256671906
31 -- 0.9667428281 -- 0.8122692916 -- 9.4123458862 -- 9.8522424698
32 -- 0.9621340832 -- 0.8254526279 -- 9.2695035934 -- 9.6692190170
33 -- 0.9645556272 -- 0.8258041835 -- 9.1195716858 -- 9.5209302902
34 -- 0.9697697580 -- 0.8108630691 -- 8.9670934677 -- 9.4201097488
35 -- 0.9707852442 -- 0.7943399543 -- 8.8264045715 -- 9.3337831497
36 -- 0.9644189271 -- 0.8270346282 -- 8.6944961548 -- 9.1131563187
37 -- 0.9732458453 -- 0.8034804008 -- 8.5432701111 -- 9.0478935242
38 -- 0.9625246548 -- 0.7604148356 -- 8.4349594116 -- 9.0483722687
39 -- 0.9720936591 -- 0.8161364036 -- 8.2730340958 -- 8.7576885223
40 -- 0.9722303591 -- 0.8215855159 -- 8.1421346664 -- 8.6113996506
41 -- 0.9737535884 -- 0.8136755142 -- 8.0092935562 -- 8.5137472153
42 -- 0.9753158748 -- 0.8106872913 -- 7.8796062469 -- 8.4047107697
43 -- 0.9793778194 -- 0.7922306205 -- 7.7584853172 -- 8.3418178558
44 -- 0.9694182436 -- 0.8280892951 -- 7.6407761574 -- 8.1288490295
45 -- 0.9778155330 -- 0.7962735103 -- 7.5099463463 -- 8.0883235931
46 -- 0.9763899467 -- 0.8154332923 -- 7.3870449066 -- 7.9340877533
47 -- 0.9765266467 -- 0.7866057304 -- 7.2778964043 -- 7.9064002037
48 -- 0.9744175601 -- 0.8194761821 -- 7.1588644981 -- 7.7035231590
49 -- 0.9793778194 -- 0.7881877307 -- 7.0442070961 -- 7.6983723640
 
btrain accuracy score = 0.979378
btest  accuracy score = 0.788188
btrain confusion matrix =
[[21942   791]
 [  265 28209]]
btest  confusion matrix =
[[1634  358]
 [ 847 2850]]
 
 
 
Trial 2 savedModels-complex/200-left/200-left
 
00 -- 0.7837362809 -- 0.8383128295 -- 27.2913513184 -- 25.3893356323
01 -- 0.8101003789 -- 0.8300527241 -- 18.3038597107 -- 17.7131862640
02 -- 0.7224934578 -- 0.7597539543 -- 16.6091556549 -- 16.3266181946
03 -- 0.8395500527 -- 0.8481546573 -- 14.7390909195 -- 14.7827377319
04 -- 0.8664609616 -- 0.8609841828 -- 14.1556272507 -- 14.2037601471
05 -- 0.8508377924 -- 0.8539543058 -- 13.8840017319 -- 13.9055423737
06 -- 0.8811272117 -- 0.8609841828 -- 13.6394920349 -- 13.7315254211
07 -- 0.8947388978 -- 0.8618629174 -- 13.4076900482 -- 13.5106601715
08 -- 0.9029215326 -- 0.8588752197 -- 13.1964464188 -- 13.3324403763
09 -- 0.9138577510 -- 0.8699472759 -- 12.9937839508 -- 13.1320066452
10 -- 0.9235441159 -- 0.8710017575 -- 12.7887353897 -- 12.9312152863
11 -- 0.9318829825 -- 0.8666080844 -- 12.5882892609 -- 12.7488031387
12 -- 0.9366480491 -- 0.8692442882 -- 12.3867292404 -- 12.5557184219
13 -- 0.9405343124 -- 0.8681898067 -- 12.1868629456 -- 12.3725996017
14 -- 0.9439909386 -- 0.8717047452 -- 11.9915065765 -- 12.1802864075
15 -- 0.9490294106 -- 0.8711775044 -- 11.7918558121 -- 11.9834060669
16 -- 0.9468616959 -- 0.8708260105 -- 11.6030426025 -- 11.7969808578
17 -- 0.9530328477 -- 0.8697715290 -- 11.4006328583 -- 11.6084432602
18 -- 0.9516462915 -- 0.8659050967 -- 11.2160291672 -- 11.4440507889
19 -- 0.9569972269 -- 0.8699472759 -- 11.0181274414 -- 11.2410783768
20 -- 0.9572511034 -- 0.8736379613 -- 10.8306722641 -- 11.0477752686
21 -- 0.9629145022 -- 0.8711775044 -- 10.6402902603 -- 10.8622446060
22 -- 0.9627973284 -- 0.8706502636 -- 10.4558553696 -- 10.6876010895
23 -- 0.9666054759 -- 0.8653778559 -- 10.2735872269 -- 10.5182666779
24 -- 0.9663320705 -- 0.8666080844 -- 10.0920228958 -- 10.3453521729
25 -- 0.9680115611 -- 0.8708260105 -- 9.9138059616 -- 10.1602897644
26 -- 0.9701206890 -- 0.8664323374 -- 9.7413692474 -- 10.0041313171
27 -- 0.9626801547 -- 0.8706502636 -- 9.5757780075 -- 9.8336925507
28 -- 0.9700621021 -- 0.8671353251 -- 9.3946847916 -- 9.6600999832
29 -- 0.9703355076 -- 0.8650263620 -- 9.2364730835 -- 9.5216512680
30 -- 0.9679725032 -- 0.8717047452 -- 9.0671195984 -- 9.3432531357
31 -- 0.9741631840 -- 0.8666080844 -- 8.8997879028 -- 9.1856040955
32 -- 0.9691051830 -- 0.8711775044 -- 8.7484016418 -- 9.0377159119
33 -- 0.9731476780 -- 0.8678383128 -- 8.5847911835 -- 8.8787984848
34 -- 0.9737335468 -- 0.8550087873 -- 8.4488000870 -- 8.7670440674
35 -- 0.9444205757 -- 0.8632688928 -- 8.3424739838 -- 8.6537008286
36 -- 0.9662734836 -- 0.8741652021 -- 8.1487960815 -- 8.4546203613
37 -- 0.9411201812 -- 0.8300527241 -- 8.0668649673 -- 8.4129981995
38 -- 0.9600046870 -- 0.8509666081 -- 7.8907313347 -- 8.2110891342
39 -- 0.9729523884 -- 0.8567662566 -- 7.7357306480 -- 8.0602912903
40 -- 0.9759207905 -- 0.8636203866 -- 7.5831465721 -- 7.9065127373
41 -- 0.9771706441 -- 0.8667838313 -- 7.4435029030 -- 7.7621793747
42 -- 0.9761746670 -- 0.8681898067 -- 7.3142194748 -- 7.6361780167
43 -- 0.9729328594 -- 0.8688927944 -- 7.1903190613 -- 7.5159978867
44 -- 0.9751005742 -- 0.8704745167 -- 7.0576291084 -- 7.3895773888
45 -- 0.9807249150 -- 0.8685413005 -- 6.9262895584 -- 7.2644891739
46 -- 0.9814865445 -- 0.8620386643 -- 6.8104195595 -- 7.1804299355
47 -- 0.9757255009 -- 0.8680140598 -- 6.6927056313 -- 7.0456147194
48 -- 0.9785767293 -- 0.8690685413 -- 6.5675535202 -- 6.9200720787
49 -- 0.9759793774 -- 0.8483304042 -- 6.4793214798 -- 6.8638782501
 
btrain accuracy score = 0.975979
btest  accuracy score = 0.848330
btrain confusion matrix =
[[22402   523]
 [  707 27574]]
btest  confusion matrix =
[[1496  304]
 [ 559 3331]]
 
 
 
Trial 3 savedModels-complex/200-left/200-left
 
00 -- 0.8155525612 -- 0.7899455089 -- 25.0647468567 -- 28.0008087158
01 -- 0.7512840041 -- 0.7887150642 -- 20.0270557404 -- 18.6793956757
02 -- 0.5798621282 -- 0.6229565829 -- 17.4930973053 -- 17.1177024841
03 -- 0.7787997735 -- 0.7428370540 -- 15.4471397400 -- 15.2299938202
04 -- 0.7972347531 -- 0.8122692916 -- 14.4371290207 -- 14.4281272888
05 -- 0.8661315836 -- 0.7968008437 -- 13.9024953842 -- 14.0821886063
06 -- 0.8760521023 -- 0.8351204078 -- 13.6097917557 -- 13.7419490814
07 -- 0.8922022380 -- 0.8180699596 -- 13.3941679001 -- 13.5844411850
08 -- 0.8901322085 -- 0.8312532958 -- 13.1915245056 -- 13.3638982773
09 -- 0.9156365341 -- 0.8330110740 -- 12.9685258865 -- 13.1695213318
10 -- 0.9229206944 -- 0.8428546317 -- 12.7572603226 -- 12.9457597733
11 -- 0.9282129396 -- 0.8456670768 -- 12.5541210175 -- 12.7579212189
12 -- 0.9352041713 -- 0.8403937423 -- 12.3501920700 -- 12.5609388351
13 -- 0.9384654442 -- 0.8463701881 -- 12.1467647552 -- 12.3637943268
14 -- 0.9444802468 -- 0.8414484092 -- 11.9415979385 -- 12.1641960144
15 -- 0.9467260336 -- 0.8417999648 -- 11.7408132553 -- 11.9722919464
16 -- 0.9511394926 -- 0.8440850765 -- 11.5375938416 -- 11.7702169418
17 -- 0.9546351085 -- 0.8430304096 -- 11.3383226395 -- 11.5734386444
18 -- 0.9552209659 -- 0.8463701881 -- 11.1382188797 -- 11.3760108948
19 -- 0.9567246665 -- 0.8458428546 -- 10.9413261414 -- 11.1952066422
20 -- 0.9604546253 -- 0.8426788539 -- 10.7462491989 -- 10.9972715378
21 -- 0.9582674244 -- 0.8417999648 -- 10.5557785034 -- 10.8265180588
22 -- 0.9638525983 -- 0.8495341888 -- 10.3637437820 -- 10.6165113449
23 -- 0.9620754975 -- 0.8437335208 -- 10.1751794815 -- 10.4579944611
24 -- 0.9674653856 -- 0.8481279663 -- 9.9876337051 -- 10.2528295517
25 -- 0.9690862577 -- 0.8439092986 -- 9.8034791946 -- 10.0776720047
26 -- 0.9664889566 -- 0.8451397434 -- 9.6225061417 -- 9.9111785889
27 -- 0.9680121858 -- 0.8490068553 -- 9.4437332153 -- 9.7365875244
28 -- 0.9711758158 -- 0.8470732993 -- 9.2687187195 -- 9.5550727844
29 -- 0.9735778312 -- 0.8476006328 -- 9.0971584320 -- 9.3803958893
30 -- 0.9716249731 -- 0.8442608543 -- 8.9260702133 -- 9.2373857498
31 -- 0.9732849025 -- 0.8483037441 -- 8.7575082779 -- 9.0606126785
32 -- 0.9712929873 -- 0.8456670768 -- 8.6103935242 -- 8.8981971741
33 -- 0.9717812018 -- 0.8428546317 -- 8.4363336563 -- 8.7543659210
34 -- 0.9757650321 -- 0.8495341888 -- 8.2748985291 -- 8.5866365433
35 -- 0.9754916320 -- 0.8521708560 -- 8.1234531403 -- 8.4248046875
36 -- 0.9759017322 -- 0.8421515205 -- 7.9659953117 -- 8.3001194000
37 -- 0.9572128811 -- 0.8263315170 -- 7.8523097038 -- 8.2711448669
38 -- 0.9438162751 -- 0.8326595184 -- 7.7398123741 -- 8.0600538254
39 -- 0.9701798582 -- 0.8504130779 -- 7.5455794334 -- 7.8968420029
40 -- 0.9687542719 -- 0.8483037441 -- 7.4173789024 -- 7.7284317017
41 -- 0.9699845724 -- 0.8470732993 -- 7.2707719803 -- 7.6137075424
42 -- 0.9728748023 -- 0.8497099666 -- 7.1336340904 -- 7.4486064911
43 -- 0.9741636886 -- 0.8409210758 -- 7.0035915375 -- 7.3183970451
44 -- 0.9730896167 -- 0.8393390754 -- 6.8752369881 -- 7.2057957649
45 -- 0.9802761341 -- 0.8467217437 -- 6.7341504097 -- 7.0704045296
46 -- 0.9803933056 -- 0.8439092986 -- 6.6129879951 -- 6.9502768517
47 -- 0.9787333763 -- 0.8439092986 -- 6.4815373421 -- 6.8505110741
48 -- 0.9809401058 -- 0.8476006328 -- 6.3594474792 -- 6.7315902710
49 -- 0.9801199055 -- 0.8468975215 -- 6.2420639992 -- 6.6161694527
 
btrain accuracy score = 0.980120
btest  accuracy score = 0.846898
btrain confusion matrix =
[[21025   921]
 [   97 29164]]
btest  confusion matrix =
[[2174  605]
 [ 266 2644]]
 
 
 
Trial 4 savedModels-complex/200-left/200-left
 
00 -- 0.8367769402 -- 0.8246045694 -- 22.4648399353 -- 21.0286407471
01 -- 0.7269070031 -- 0.7926186292 -- 21.0223426819 -- 19.1769523621
02 -- 0.8580635082 -- 0.8613356766 -- 15.3731994629 -- 15.0315818787
03 -- 0.8046713276 -- 0.8312829525 -- 14.9632358551 -- 14.8538131714
04 -- 0.7971331485 -- 0.8309314587 -- 14.5434856415 -- 14.3515138626
05 -- 0.8662070851 -- 0.8400702988 -- 13.9793634415 -- 14.0490608215
06 -- 0.8784517439 -- 0.8463971880 -- 13.7314872742 -- 13.8196401596
07 -- 0.8935476311 -- 0.8618629174 -- 13.5405521393 -- 13.6148281097
08 -- 0.8980783502 -- 0.8543057996 -- 13.3530378342 -- 13.4590387344
09 -- 0.9081162364 -- 0.8465729350 -- 13.1756706238 -- 13.3268804550
10 -- 0.9127836582 -- 0.8634446397 -- 12.9873342514 -- 13.1051511765
11 -- 0.9247353826 -- 0.8557117750 -- 12.7988204956 -- 12.9513187408
12 -- 0.9269812131 -- 0.8546572935 -- 12.6200494766 -- 12.7869548798
13 -- 0.9341678710 -- 0.8537785589 -- 12.4325151443 -- 12.6049737930
14 -- 0.9358668906 -- 0.8569420035 -- 12.2505149841 -- 12.4321928024
15 -- 0.9397726829 -- 0.8506151142 -- 12.0692100525 -- 12.2671165466
16 -- 0.9419794555 -- 0.8483304042 -- 11.8874912262 -- 12.0950946808
17 -- 0.9439323517 -- 0.8581722320 -- 11.7058162689 -- 11.9080419540
18 -- 0.9483263680 -- 0.8520210896 -- 11.5220899582 -- 11.7353096008
19 -- 0.9499472718 -- 0.8601054482 -- 11.3416643143 -- 11.5525026321
20 -- 0.9538335351 -- 0.8590509666 -- 11.1617069244 -- 11.3755006790
21 -- 0.9578565012 -- 0.8555360281 -- 10.9847793579 -- 11.2051811218
22 -- 0.9588720072 -- 0.8590509666 -- 10.8098411560 -- 11.0275278091
23 -- 0.9592625864 -- 0.8599297012 -- 10.6338882446 -- 10.8651399612
24 -- 0.9626020388 -- 0.8594024605 -- 10.4612855911 -- 10.7002105713
25 -- 0.9631879077 -- 0.8567662566 -- 10.2912387848 -- 10.5281925201
26 -- 0.9636761317 -- 0.8495606327 -- 10.1242141724 -- 10.3879947662
27 -- 0.9659805492 -- 0.8541300527 -- 9.9551925659 -- 10.2220726013
28 -- 0.9673671054 -- 0.8590509666 -- 9.7896633148 -- 10.0519037247
29 -- 0.9694176464 -- 0.8581722320 -- 9.6266145706 -- 9.8882837296
30 -- 0.9696324649 -- 0.8571177504 -- 9.4686441422 -- 9.7278451920
31 -- 0.9671327579 -- 0.8528998243 -- 9.3110771179 -- 9.6012182236
32 -- 0.9711166660 -- 0.8567662566 -- 9.1544189453 -- 9.4233388901
33 -- 0.9626996836 -- 0.8391915641 -- 9.0113811493 -- 9.3451070786
34 -- 0.9727961567 -- 0.8537785589 -- 8.8462810516 -- 9.1412134171
35 -- 0.9771706441 -- 0.8557117750 -- 8.7001810074 -- 8.9830083847
36 -- 0.9735382572 -- 0.8578207381 -- 8.5522928238 -- 8.8480195999
37 -- 0.9743780026 -- 0.8560632689 -- 8.4065656662 -- 8.7082071304
38 -- 0.9760379643 -- 0.8537785589 -- 8.2632417679 -- 8.5760345459
39 -- 0.9766238331 -- 0.8504393673 -- 8.1233348846 -- 8.4502906799
40 -- 0.9720735851 -- 0.8404217926 -- 7.9916543961 -- 8.3559904099
41 -- 0.9778541577 -- 0.8502636204 -- 7.8497424126 -- 8.1872215271
42 -- 0.9743194157 -- 0.8530755712 -- 7.7460947037 -- 8.0503177643
43 -- 0.9548685701 -- 0.8181019332 -- 7.6389732361 -- 8.0805873871
44 -- 0.9613521853 -- 0.8523725835 -- 7.5208005905 -- 7.8588781357
45 -- 0.9340702261 -- 0.8165202109 -- 7.4602284431 -- 7.8503570557
46 -- 0.9600828028 -- 0.8425307557 -- 7.2721753120 -- 7.6007623672
47 -- 0.9705503261 -- 0.8544815466 -- 7.1165924072 -- 7.4370718002
48 -- 0.9627192126 -- 0.8398945518 -- 7.0097818375 -- 7.3891568184
49 -- 0.9732062649 -- 0.8428822496 -- 6.8757491112 -- 7.2397203445
 
btrain accuracy score = 0.973206
btest  accuracy score = 0.842882
btrain confusion matrix =
[[20200  1309]
 [   63 29634]]
btest  confusion matrix =
[[2534  682]
 [ 212 2262]]
 
 
 
Trial 5 savedModels-complex/200-left/200-left
 
00 -- 0.8246885131 -- 0.7636203866 -- 26.2308387756 -- 26.8126029968
01 -- 0.8312307152 -- 0.7618629174 -- 16.0642127991 -- 22.2885036469
02 -- 0.8712846151 -- 0.7771528998 -- 15.0520124435 -- 17.8769454956
03 -- 0.8643127758 -- 0.7792618629 -- 14.8337059021 -- 16.2667045593
04 -- 0.7749287193 -- 0.7163444640 -- 14.2527246475 -- 16.1296997070
05 -- 0.8939186814 -- 0.7804920914 -- 13.7429285049 -- 14.9888076782
06 -- 0.8955200562 -- 0.7950790861 -- 13.3742094040 -- 14.0650539398
07 -- 0.9120415576 -- 0.7760984183 -- 13.0560379028 -- 14.1509227753
08 -- 0.9086825763 -- 0.7954305800 -- 12.8279800415 -- 13.4008054733
09 -- 0.9300082022 -- 0.7826010545 -- 12.5173778534 -- 13.2863740921
10 -- 0.9338749365 -- 0.7717047452 -- 12.2772397995 -- 13.1127948761
11 -- 0.9436003593 -- 0.7680140598 -- 12.0336523056 -- 12.8200302124
12 -- 0.9486193024 -- 0.7720562390 -- 11.7918062210 -- 12.5992412567
13 -- 0.9529156739 -- 0.7829525483 -- 11.5535564423 -- 12.2695980072
14 -- 0.9544194040 -- 0.7840070299 -- 11.3199405670 -- 12.0555562973
15 -- 0.9579346170 -- 0.7859402460 -- 11.0847682953 -- 11.8092184067
16 -- 0.9603562083 -- 0.7824253076 -- 10.8518371582 -- 11.6034755707
17 -- 0.9639300082 -- 0.7750439367 -- 10.6248102188 -- 11.4452466965
18 -- 0.9652579776 -- 0.7759226714 -- 10.3981304169 -- 11.2373285294
19 -- 0.9672694606 -- 0.7827768014 -- 10.1737823486 -- 10.9504489899
20 -- 0.9687927196 -- 0.7840070299 -- 9.9538564682 -- 10.7276725769
21 -- 0.9693004726 -- 0.7887521968 -- 9.7381181717 -- 10.4945402145
22 -- 0.9746318791 -- 0.7697715290 -- 9.5320396423 -- 10.3417320251
23 -- 0.9724641644 -- 0.7769771529 -- 9.3172922134 -- 10.1796207428
24 -- 0.9721321720 -- 0.7843585237 -- 9.1116018295 -- 9.9027280807
25 -- 0.9713119556 -- 0.7894551845 -- 8.9117059708 -- 9.6623020172
26 -- 0.9714681873 -- 0.7891036907 -- 8.7130870819 -- 9.4879112244
27 -- 0.9761356091 -- 0.7783831283 -- 8.5181407928 -- 9.3998203278
28 -- 0.9755302113 -- 0.7796133568 -- 8.3306665421 -- 9.2503852844
29 -- 0.9688903644 -- 0.7894551845 -- 8.1522569656 -- 8.9843473434
30 -- 0.9761356091 -- 0.7799648506 -- 7.9618077278 -- 8.8688669205
31 -- 0.9670546420 -- 0.7395430580 -- 7.8259906769 -- 8.8495912552
32 -- 0.8096902707 -- 0.7806678383 -- 8.1185531616 -- 8.4153919220
33 -- 0.9430340195 -- 0.7857644991 -- 7.5531959534 -- 8.5141315460
34 -- 0.9646135219 -- 0.7695957821 -- 7.3228430748 -- 8.4010972977
35 -- 0.9440690544 -- 0.7249560633 -- 7.2109403610 -- 8.2816648483
36 -- 0.9732257939 -- 0.7715289982 -- 6.9949216843 -- 7.9584846497
37 -- 0.9745342343 -- 0.7804920914 -- 6.8345947266 -- 7.6999692917
38 -- 0.9759207905 -- 0.7869947276 -- 6.6819510460 -- 7.4949026108
39 -- 0.9742022419 -- 0.7913884007 -- 6.5379405022 -- 7.3206477165
40 -- 0.9750224583 -- 0.7889279438 -- 6.3945918083 -- 7.2294578552
41 -- 0.9796117642 -- 0.7848857645 -- 6.2484831810 -- 7.0967106819
42 -- 0.9811545522 -- 0.7762741652 -- 6.1120262146 -- 7.0479187965
43 -- 0.9810373784 -- 0.7808435852 -- 5.9775233269 -- 6.8951458931
44 -- 0.9834199117 -- 0.7782073814 -- 5.8480491638 -- 6.7994842529
45 -- 0.9837519041 -- 0.7771528998 -- 5.7197079659 -- 6.6535153389
46 -- 0.9793383588 -- 0.7908611599 -- 5.5999345779 -- 6.4581956863
47 -- 0.9850798735 -- 0.7745166960 -- 5.4742126465 -- 6.4176192284
48 -- 0.9847478811 -- 0.7683655536 -- 5.3610067368 -- 6.3941979408
49 -- 0.9743584736 -- 0.7991212654 -- 5.2555527687 -- 6.0585050583
 
btrain accuracy score = 0.974358
btest  accuracy score = 0.799121
btrain confusion matrix =
[[21304  1295]
 [   18 28589]]
btest  confusion matrix =
[[1781  345]
 [ 798 2766]]
 
 
 
Trial 6 savedModels-complex/200-left/200-left
 
00 -- 0.8071162146 -- 0.8347688522 -- 23.1364517212 -- 20.5059318542
01 -- 0.8352178413 -- 0.8620144138 -- 15.9642391205 -- 15.8006992340
02 -- 0.8544144355 -- 0.8688697486 -- 15.1266155243 -- 14.8915195465
03 -- 0.7842873045 -- 0.8326595184 -- 14.6363000870 -- 14.4100713730
04 -- 0.8606245240 -- 0.8502373001 -- 13.9366521835 -- 13.9739189148
05 -- 0.8531450778 -- 0.8558621902 -- 13.7608518600 -- 13.8343391418
06 -- 0.8760130451 -- 0.8692213043 -- 13.4474945068 -- 13.5870056152
07 -- 0.9084304880 -- 0.8760766391 -- 13.0800256729 -- 13.2412719727
08 -- 0.9138399047 -- 0.8876779750 -- 12.8445568085 -- 12.9899301529
09 -- 0.9252641240 -- 0.8776586395 -- 12.6019897461 -- 12.8053197861
10 -- 0.9315523268 -- 0.8827561962 -- 12.3695497513 -- 12.5636634827
11 -- 0.9346183139 -- 0.8795921955 -- 12.1388378143 -- 12.3461446762
12 -- 0.9340324565 -- 0.8790648620 -- 11.9159259796 -- 12.1315975189
13 -- 0.9448317613 -- 0.8864475303 -- 11.6666030884 -- 11.8830528259
14 -- 0.9397933876 -- 0.8644753032 -- 11.4506540298 -- 11.6952714920
15 -- 0.9469408479 -- 0.8732641941 -- 11.2167415619 -- 11.4583196640
16 -- 0.9531899936 -- 0.8815257515 -- 10.9826612473 -- 11.2251005173
17 -- 0.9556896518 -- 0.8841624187 -- 10.7590303421 -- 11.0037784576
18 -- 0.9490694632 -- 0.8657057479 -- 10.5600776672 -- 10.8226757050
19 -- 0.9585603531 -- 0.8818773071 -- 10.3219194412 -- 10.5964336395
20 -- 0.9632862695 -- 0.8855686412 -- 10.1052150726 -- 10.3726320267
21 -- 0.9655125276 -- 0.8813499736 -- 9.8941640854 -- 10.1781082153
22 -- 0.9667428281 -- 0.8822288627 -- 9.6876726151 -- 9.9747762680
23 -- 0.9604155682 -- 0.8831077518 -- 9.4912891388 -- 9.7840681076
24 -- 0.9705899584 -- 0.8802953067 -- 9.2833309174 -- 9.5914964676
25 -- 0.9657859277 -- 0.8846897522 -- 9.0913305283 -- 9.3882246017
26 -- 0.9707852442 -- 0.8850413078 -- 8.8929538727 -- 9.1881875992
27 -- 0.9734606597 -- 0.8804710845 -- 8.7050848007 -- 9.0058336258
28 -- 0.9733825454 -- 0.8783617507 -- 8.5214300156 -- 8.8349504471
29 -- 0.9709805300 -- 0.8827561962 -- 8.3382539749 -- 8.6557788849
30 -- 0.9643798699 -- 0.8790648620 -- 8.1723623276 -- 8.5193557739
31 -- 0.9642236413 -- 0.8808226402 -- 7.9994254112 -- 8.3394794464
32 -- 0.9663131994 -- 0.8815257515 -- 7.8272066116 -- 8.1725111008
33 -- 0.9669576425 -- 0.8555106346 -- 7.6782360077 -- 8.0227308273
34 -- 0.9660983850 -- 0.8829319740 -- 7.5015258789 -- 7.8592662811
35 -- 0.9756088035 -- 0.8801195289 -- 7.3242197037 -- 7.6692895889
36 -- 0.9776788330 -- 0.8699244155 -- 7.1740250587 -- 7.5512599945
37 -- 0.9788505478 -- 0.8762524169 -- 7.0154838562 -- 7.3841814995
38 -- 0.9652391275 -- 0.8794164176 -- 6.8915138245 -- 7.2822360992
39 -- 0.9793778194 -- 0.8757250835 -- 6.7193021774 -- 7.1042990685
40 -- 0.9817993634 -- 0.8759008613 -- 6.5768136978 -- 6.9702358246
41 -- 0.9794168766 -- 0.8727368606 -- 6.4400587082 -- 6.8294601440
42 -- 0.9808034058 -- 0.8743188610 -- 6.3018875122 -- 6.6919651031
43 -- 0.9404378308 -- 0.8562137458 -- 6.2471480370 -- 6.6269512177
44 -- 0.9458667760 -- 0.8894357532 -- 6.1617212296 -- 6.4711570740
45 -- 0.8829456910 -- 0.8542801898 -- 6.3309350014 -- 6.6758913994
46 -- 0.9177846779 -- 0.8820530849 -- 6.0498218536 -- 6.2996621132
47 -- 0.9230964517 -- 0.8486552997 -- 5.8233866692 -- 6.1067204475
48 -- 0.9291698401 -- 0.8648268589 -- 5.7148113251 -- 6.0721621513
49 -- 0.9460620618 -- 0.8293197398 -- 5.5606093407 -- 5.9243621826
 
btrain accuracy score = 0.946062
btest  accuracy score = 0.829320
btrain confusion matrix =
[[21998   688]
 [ 2074 26447]]
btest  confusion matrix =
[[1774  265]
 [ 706 2944]]
 
 
 
Trial 7 savedModels-complex/200-left/200-left
 
00 -- 0.8095145100 -- 0.7783831283 -- 23.0188713074 -- 25.5623874664
01 -- 0.7873881967 -- 0.7764499121 -- 19.4024715424 -- 21.4016418457
02 -- 0.8157442487 -- 0.7889279438 -- 15.5253524780 -- 15.8655738831
03 -- 0.8035581768 -- 0.7360281195 -- 14.9085111618 -- 16.3479728699
04 -- 0.8512283717 -- 0.7543057996 -- 14.3460903168 -- 15.3608827591
05 -- 0.8427918603 -- 0.7701230228 -- 14.0170907974 -- 14.7884082794
06 -- 0.8754052260 -- 0.7434094903 -- 13.6999368668 -- 14.3844394684
07 -- 0.8932351678 -- 0.7636203866 -- 13.4910736084 -- 14.2098808289
08 -- 0.9013787447 -- 0.7562390158 -- 13.2951469421 -- 13.9413862228
09 -- 0.9110455806 -- 0.7776801406 -- 13.1037864685 -- 13.7001399994
10 -- 0.9184470570 -- 0.7718804921 -- 12.9099740982 -- 13.5214319229
11 -- 0.9262195836 -- 0.7702987698 -- 12.7206649780 -- 13.3353939056
12 -- 0.9265125181 -- 0.7780316344 -- 12.5380525589 -- 13.1991004944
13 -- 0.9365113463 -- 0.7738137083 -- 12.3416929245 -- 12.9569425583
14 -- 0.9329766043 -- 0.7829525483 -- 12.1611728668 -- 12.7306442261
15 -- 0.9337968207 -- 0.7653778559 -- 11.9829025269 -- 12.6955099106
16 -- 0.9424872085 -- 0.7787346221 -- 11.7849111557 -- 12.4579763412
17 -- 0.9450064446 -- 0.7822495606 -- 11.6032676697 -- 12.1778049469
18 -- 0.9464711167 -- 0.7738137083 -- 11.4185628891 -- 12.1199769974
19 -- 0.9527399133 -- 0.7792618629 -- 11.2309436798 -- 11.9175243378
20 -- 0.9508846620 -- 0.7748681898 -- 11.0572071075 -- 11.6696138382
21 -- 0.9357497168 -- 0.7637961336 -- 10.9076356888 -- 11.7072000504
22 -- 0.9431121353 -- 0.7824253076 -- 10.7224397659 -- 11.5095081329
23 -- 0.9539116510 -- 0.7729349736 -- 10.5311384201 -- 11.1693553925
24 -- 0.9428192009 -- 0.7822495606 -- 10.3756132126 -- 10.9942846298
25 -- 0.9554739679 -- 0.7787346221 -- 10.1963205338 -- 10.7968416214
26 -- 0.9633246104 -- 0.7810193322 -- 10.0138206482 -- 10.6691436768
27 -- 0.9619575831 -- 0.7826010545 -- 9.8472337723 -- 10.5833768845
28 -- 0.9661758388 -- 0.7780316344 -- 9.6805276871 -- 10.4085206985
29 -- 0.9637347186 -- 0.7799648506 -- 9.5292024612 -- 10.1869983673
30 -- 0.9698472835 -- 0.7818980668 -- 9.3564081192 -- 10.0851993561
31 -- 0.9713705425 -- 0.7813708260 -- 9.1990671158 -- 9.9120178223
32 -- 0.9741045971 -- 0.7739894552 -- 9.0466108322 -- 9.7475395203
33 -- 0.9729133305 -- 0.7804920914 -- 8.8904981613 -- 9.6517305374
34 -- 0.9743389447 -- 0.7817223199 -- 8.7395668030 -- 9.4773607254
35 -- 0.9761160801 -- 0.7799648506 -- 8.5904607773 -- 9.3422956467
36 -- 0.9748857556 -- 0.7797891037 -- 8.4455881119 -- 9.2177457809
37 -- 0.9769948834 -- 0.7820738137 -- 8.3018770218 -- 9.0494165421
38 -- 0.9758622036 -- 0.7864674868 -- 8.1608839035 -- 8.9210720062
39 -- 0.9777174550 -- 0.7850615114 -- 8.0244703293 -- 8.7695207596
40 -- 0.9777174550 -- 0.7824253076 -- 7.8831920624 -- 8.6709823608
41 -- 0.9753935086 -- 0.7792618629 -- 7.7525472641 -- 8.6031799316
42 -- 0.9801976331 -- 0.7789103691 -- 7.6153903008 -- 8.4293203354
43 -- 0.9791430692 -- 0.7764499121 -- 7.4863867760 -- 8.3406352997
44 -- 0.9779127446 -- 0.7789103691 -- 7.3599734306 -- 8.2404623032
45 -- 0.9820724134 -- 0.7887521968 -- 7.2311110497 -- 8.0350418091
46 -- 0.9844744756 -- 0.7838312830 -- 7.1070165634 -- 7.9061107635
47 -- 0.9835566145 -- 0.7810193322 -- 6.9840340614 -- 7.8282036781
48 -- 0.9728156857 -- 0.7820738137 -- 6.8804826736 -- 7.8396286964
49 -- 0.9819747686 -- 0.7866432337 -- 6.7586565018 -- 7.5585055351
 
btrain accuracy score = 0.981975
btest  accuracy score = 0.786643
btrain confusion matrix =
[[21334   520]
 [  403 28949]]
btest  confusion matrix =
[[2022  849]
 [ 365 2454]]
 
 
 
Trial 8 savedModels-complex/200-left/200-left
 
00 -- 0.8170562618 -- 0.7811566180 -- 24.2914924622 -- 27.9994449615
01 -- 0.8383619427 -- 0.7779926173 -- 16.8652687073 -- 17.6201744080
02 -- 0.7993438397 -- 0.7688521709 -- 15.6096172333 -- 15.4551401138
03 -- 0.8780635460 -- 0.8539286342 -- 14.4184465408 -- 14.5881605148
04 -- 0.8372488136 -- 0.7902970645 -- 13.9784317017 -- 14.0844898224
05 -- 0.8750756732 -- 0.8071717349 -- 13.7642374039 -- 14.1008090973
06 -- 0.8793719609 -- 0.8143786254 -- 13.4321422577 -- 13.6738634109
07 -- 0.8888433222 -- 0.7797503955 -- 13.1577596664 -- 13.4136657715
08 -- 0.9031968286 -- 0.8584988574 -- 12.9100255966 -- 13.0867958069
09 -- 0.9163200344 -- 0.8284408508 -- 12.6722536087 -- 12.8785314560
10 -- 0.9282129396 -- 0.8229917384 -- 12.4361629486 -- 12.6792755127
11 -- 0.9369226864 -- 0.8477764106 -- 12.2052116394 -- 12.4321804047
12 -- 0.9464135763 -- 0.8562137458 -- 11.9676284790 -- 12.2360782623
13 -- 0.9527213076 -- 0.8588504131 -- 11.7383785248 -- 12.0124082565
14 -- 0.9557872947 -- 0.8509404113 -- 11.5154638290 -- 11.7848157883
15 -- 0.9590485676 -- 0.8541044120 -- 11.2911329269 -- 11.5875053406
16 -- 0.9626808835 -- 0.8544559677 -- 11.0692081451 -- 11.3541221619
17 -- 0.9636768411 -- 0.8562137458 -- 10.8498735428 -- 11.1459360123
18 -- 0.9530142363 -- 0.8407452979 -- 10.6523475647 -- 11.0021228790
19 -- 0.9675825571 -- 0.8526981895 -- 10.4210233688 -- 10.7230539322
20 -- 0.9629542836 -- 0.8490068553 -- 10.2134323120 -- 10.5625886917
21 -- 0.9668014139 -- 0.8541044120 -- 10.0031528473 -- 10.3444824219
22 -- 0.9718397875 -- 0.8226401828 -- 9.8088130951 -- 10.1411895752
23 -- 0.9547327514 -- 0.8338899631 -- 9.6259250641 -- 10.0203733444
24 -- 0.9652977132 -- 0.8268588504 -- 9.4198732376 -- 9.7433652878
25 -- 0.9228035230 -- 0.8026015117 -- 9.3175506592 -- 9.8120212555
26 -- 0.8942332103 -- 0.7899455089 -- 9.2882270813 -- 9.8785305023
27 -- 0.8984709122 -- 0.7867815082 -- 9.0859079361 -- 9.6442508698
28 -- 0.7967074814 -- 0.7757075057 -- 9.4339256287 -- 9.5846920013
29 -- 0.8966156971 -- 0.8061170680 -- 8.8326654434 -- 9.3757467270
30 -- 0.9440506181 -- 0.8555106346 -- 8.4072093964 -- 8.7153272629
31 -- 0.9519596930 -- 0.8504130779 -- 8.2164325714 -- 8.5394916534
32 -- 0.9510027926 -- 0.8476006328 -- 8.0526504517 -- 8.4244737625
33 -- 0.9538149081 -- 0.8349446300 -- 7.8881044388 -- 8.2802057266
34 -- 0.9662546136 -- 0.8518193004 -- 7.7146921158 -- 8.0493011475
35 -- 0.9698869295 -- 0.8600808578 -- 7.5538568497 -- 7.8685631752
36 -- 0.9736559455 -- 0.8481279663 -- 7.4023184776 -- 7.7245974541
37 -- 0.9680512430 -- 0.8507646335 -- 7.2535605431 -- 7.6492137909
38 -- 0.9750034175 -- 0.8567410793 -- 7.0988245010 -- 7.4637832642
39 -- 0.9768781612 -- 0.8556864124 -- 6.9551954269 -- 7.3191857338
40 -- 0.9761556037 -- 0.8604324134 -- 6.8157649040 -- 7.1927690506
41 -- 0.9762532466 -- 0.8565653015 -- 6.6792907715 -- 7.0677580833
42 -- 0.9781084617 -- 0.8549833011 -- 6.5434951782 -- 6.9276556969
43 -- 0.9755502177 -- 0.8518193004 -- 6.4164595604 -- 6.8233036995
44 -- 0.9780498760 -- 0.8507646335 -- 6.2845892906 -- 6.7034878731
45 -- 0.9771515613 -- 0.8525224117 -- 6.1592745781 -- 6.5803227425
46 -- 0.9809205773 -- 0.8518193004 -- 6.0333466530 -- 6.4469900131
47 -- 0.9828148495 -- 0.8474248550 -- 5.9119191170 -- 6.3334889412
48 -- 0.9801784912 -- 0.8539286342 -- 5.7954149246 -- 6.2263250351
49 -- 0.9837131642 -- 0.8395148532 -- 5.6782894135 -- 6.1057996750
 
btrain accuracy score = 0.983713
btest  accuracy score = 0.839515
btrain confusion matrix =
[[21124   696]
 [  138 29249]]
btest  confusion matrix =
[[2296  609]
 [ 304 2480]]
 
 
 
Trial 9 savedModels-complex/200-left/200-left
 
00 -- 0.7777994766 -- 0.7915641476 -- 22.2674846649 -- 21.5476016998
01 -- 0.8075225560 -- 0.8117750439 -- 19.9932498932 -- 19.9365940094
02 -- 0.8246494551 -- 0.8634446397 -- 15.7813282013 -- 15.6380558014
03 -- 0.8355661446 -- 0.8156414763 -- 14.6869554520 -- 14.7292451859
04 -- 0.8591180721 -- 0.8463971880 -- 14.3160190582 -- 14.3159904480
05 -- 0.8536499629 -- 0.8427065026 -- 13.9675168991 -- 14.0789728165
06 -- 0.8649181737 -- 0.8688927944 -- 13.7386798859 -- 13.7441635132
07 -- 0.8868491974 -- 0.8537785589 -- 13.5051240921 -- 13.6092491150
08 -- 0.8999140726 -- 0.8729349736 -- 13.3077859879 -- 13.3849000931
09 -- 0.9112213412 -- 0.8653778559 -- 13.1111507416 -- 13.2223711014
10 -- 0.9154591259 -- 0.8630931459 -- 12.9195623398 -- 13.0366954803
11 -- 0.9233292973 -- 0.8704745167 -- 12.7247228622 -- 12.8397178650
12 -- 0.9276061399 -- 0.8729349736 -- 12.5327920914 -- 12.6593208313
13 -- 0.9310237082 -- 0.8676625659 -- 12.3434467316 -- 12.4881591797
14 -- 0.9367652228 -- 0.8674868190 -- 12.1503314972 -- 12.3066453934
15 -- 0.9395383354 -- 0.8660808436 -- 11.9600076675 -- 12.1263208389
16 -- 0.9403585517 -- 0.8653778559 -- 11.7741928101 -- 11.9493484497
17 -- 0.9451236183 -- 0.8727592267 -- 11.5817594528 -- 11.7516155243
18 -- 0.9475842675 -- 0.8755711775 -- 11.3946599960 -- 11.5633172989
19 -- 0.9506307855 -- 0.8762741652 -- 11.2085752487 -- 11.3853778839
20 -- 0.9539507089 -- 0.8782073814 -- 11.0262126923 -- 11.2007064819
21 -- 0.9539507089 -- 0.8710017575 -- 10.8434686661 -- 11.0454654694
22 -- 0.9580322618 -- 0.8718804921 -- 10.6617002487 -- 10.8547201157
23 -- 0.9599070421 -- 0.8745166960 -- 10.4871110916 -- 10.6808319092
24 -- 0.9606686716 -- 0.8794376098 -- 10.3107061386 -- 10.4997482300
25 -- 0.9495371636 -- 0.8871704745 -- 10.1642303467 -- 10.3275594711
26 -- 0.9452407921 -- 0.8571177504 -- 9.9917621613 -- 10.2417240143
27 -- 0.9635980159 -- 0.8840070299 -- 9.8043489456 -- 9.9973602295
28 -- 0.9646135219 -- 0.8743409490 -- 9.6294832230 -- 9.8546028137
29 -- 0.9659024333 -- 0.8743409490 -- 9.4657211304 -- 9.6931734085
30 -- 0.9663906573 -- 0.8818980668 -- 9.3133411407 -- 9.5153617859
31 -- 0.9670546420 -- 0.8685413005 -- 9.1493110657 -- 9.3976440430
32 -- 0.9662734836 -- 0.8681898067 -- 8.9939975739 -- 9.2565202713
33 -- 0.9692614147 -- 0.8731107206 -- 8.8381891251 -- 9.0873107910
34 -- 0.9720345272 -- 0.8796133568 -- 8.6870708466 -- 8.9285583496
35 -- 0.9606882006 -- 0.8702987698 -- 8.5744256973 -- 8.8071060181
36 -- 0.9522126313 -- 0.8602811951 -- 8.4370594025 -- 8.7255582809
37 -- 0.9587548334 -- 0.8729349736 -- 8.2823600769 -- 8.5588998795
38 -- 0.8296488693 -- 0.7803163445 -- 8.6316442490 -- 9.1006565094
39 -- 0.8220716322 -- 0.8680140598 -- 8.3895244598 -- 8.4126815796
40 -- 0.9292465727 -- 0.8490333919 -- 8.0072479248 -- 8.2513904572
41 -- 0.9532281373 -- 0.8724077329 -- 7.7723398209 -- 8.0197820663
42 -- 0.9577783853 -- 0.8622144112 -- 7.6457653046 -- 7.9223537445
43 -- 0.9665468890 -- 0.8690685413 -- 7.4996585846 -- 7.7606682777
44 -- 0.9668398235 -- 0.8711775044 -- 7.3750586510 -- 7.6390247345
45 -- 0.9708823185 -- 0.8759226714 -- 7.2467436790 -- 7.5064563751
46 -- 0.9727570988 -- 0.8757469244 -- 7.1244001389 -- 7.3944139481
47 -- 0.9724836933 -- 0.8711775044 -- 7.0042533875 -- 7.2922286987
48 -- 0.9717025349 -- 0.8660808436 -- 6.8893203735 -- 7.2005577087
49 -- 0.9751201031 -- 0.8736379613 -- 6.7723565102 -- 7.0622715950
 
btrain accuracy score = 0.975120
btest  accuracy score = 0.873638
btrain confusion matrix =
[[20951  1101]
 [  173 28981]]
btest  confusion matrix =
[[2129  544]
 [ 175 2842]]
 
 
 
Trial 10 savedModels-complex/200-left/200-left
 
00 -- 0.7927781901 -- 0.8080843585 -- 24.4369277954 -- 24.8300113678
01 -- 0.8013709331 -- 0.8226713533 -- 19.0920162201 -- 18.3820075989
02 -- 0.8273444518 -- 0.8829525483 -- 15.5942926407 -- 14.9391250610
03 -- 0.7718431434 -- 0.7442882250 -- 15.3115739822 -- 15.3316078186
04 -- 0.8123462094 -- 0.8715289982 -- 14.4513921738 -- 14.2990102768
05 -- 0.8551341640 -- 0.8959578207 -- 14.0353899002 -- 13.9585990906
06 -- 0.8661289693 -- 0.8722319859 -- 13.7766675949 -- 13.8234243393
07 -- 0.8648986447 -- 0.8710017575 -- 13.6140918732 -- 13.6746454239
08 -- 0.8895441940 -- 0.8866432337 -- 13.4021196365 -- 13.4657468796
09 -- 0.8996601961 -- 0.8971880492 -- 13.2312374115 -- 13.2899990082
10 -- 0.9051868922 -- 0.9021089631 -- 13.0558881760 -- 13.1170434952
11 -- 0.9138577510 -- 0.8906854130 -- 12.8736038208 -- 12.9730377197
12 -- 0.9181541226 -- 0.8891036907 -- 12.6979637146 -- 12.8052330017
13 -- 0.9225871968 -- 0.9001757469 -- 12.5244722366 -- 12.6231126785
14 -- 0.9278014295 -- 0.8971880492 -- 12.3451995850 -- 12.4585809708
15 -- 0.9318048666 -- 0.8992970123 -- 12.1713962555 -- 12.2898120880
16 -- 0.9345389212 -- 0.9026362039 -- 11.9958610535 -- 12.1161985397
17 -- 0.9373901496 -- 0.8804920914 -- 11.8205909729 -- 11.9750556946
18 -- 0.9409444206 -- 0.8959578207 -- 11.6476879120 -- 11.7884340286
19 -- 0.9430730774 -- 0.8838312830 -- 11.4717407227 -- 11.6345424652
20 -- 0.9442448151 -- 0.8961335677 -- 11.3016433716 -- 11.4488620758
21 -- 0.9489317658 -- 0.8836555360 -- 11.1285648346 -- 11.3048334122
22 -- 0.9497129243 -- 0.8753954306 -- 10.9615640640 -- 11.1576013565
23 -- 0.9514900598 -- 0.8942003515 -- 10.7911701202 -- 10.9627704620
24 -- 0.9538530641 -- 0.8787346221 -- 10.6263761520 -- 10.8298225403
25 -- 0.9561379526 -- 0.8708260105 -- 10.4635210037 -- 10.6846847534
26 -- 0.9579932039 -- 0.8892794376 -- 10.2965106964 -- 10.4954071045
27 -- 0.9605905558 -- 0.8759226714 -- 10.1376609802 -- 10.3687477112
28 -- 0.9575830957 -- 0.8885764499 -- 9.9774570465 -- 10.1865091324
29 -- 0.9610983088 -- 0.8915641476 -- 9.8175344467 -- 10.0287036896
30 -- 0.9575049799 -- 0.8943760984 -- 9.6682348251 -- 9.8739461899
31 -- 0.9631488497 -- 0.8912126538 -- 9.5083951950 -- 9.7288141251
32 -- 0.9659805492 -- 0.8871704745 -- 9.3561878204 -- 9.5849208832
33 -- 0.9644377612 -- 0.8896309315 -- 9.2072067261 -- 9.4405765533
34 -- 0.9579346170 -- 0.8980667838 -- 9.0748481750 -- 9.2826519012
35 -- 0.9244424482 -- 0.8165202109 -- 8.9952173233 -- 9.3475275040
36 -- 0.9324688513 -- 0.9094903339 -- 8.8931856155 -- 9.0185165405
37 -- 0.8806585166 -- 0.7731107206 -- 8.7858486176 -- 9.1029834747
38 -- 0.9448502129 -- 0.8769771529 -- 8.5515413284 -- 8.7843389511
39 -- 0.9564894739 -- 0.9029876977 -- 8.3909254074 -- 8.5854330063
40 -- 0.9601609186 -- 0.8940246046 -- 8.2561702728 -- 8.4825277328
41 -- 0.9646916377 -- 0.8919156415 -- 8.1157341003 -- 8.3520889282
42 -- 0.9699058704 -- 0.8854130053 -- 7.9814219475 -- 8.2423563004
43 -- 0.9711947819 -- 0.8808435852 -- 7.8531327248 -- 8.1282701492
44 -- 0.9740069523 -- 0.8771528998 -- 7.7276773453 -- 8.0187740326
45 -- 0.9736554310 -- 0.8776801406 -- 7.6025032997 -- 7.8980493546
46 -- 0.9729523884 -- 0.8848857645 -- 7.4801945686 -- 7.7641696930
47 -- 0.9727570988 -- 0.8871704745 -- 7.3613114357 -- 7.6420412064
48 -- 0.9753153927 -- 0.8813708260 -- 7.2422828674 -- 7.5416340828
49 -- 0.9747099949 -- 0.8817223199 -- 7.1264395714 -- 7.4271502495
 
btrain accuracy score = 0.974710
btest  accuracy score = 0.881722
btrain confusion matrix =
[[21235  1166]
 [  129 28676]]
btest  confusion matrix =
[[2015  309]
 [ 364 3002]]
 
 
Both Train Confusion Vals
Miss Rate   = 0.040490
Fallout     = 0.014046
Precision   = 0.981308
Recall      = 0.959510
Accuracy    = 0.974462
Specificity = 0.985954
Both Test Confusion Vals
Miss Rate   = 0.196967
Fallout     = 0.142862
Precision   = 0.812032
Recall      = 0.803033
Accuracy    = 0.833626
Specificity = 0.857138
Both Test Confusion Matrix
[[ 19855.   4870.]
 [  4596.  27575.]]
 
average train score   = 
[ 0.          0.          0.97446219]
average test score    = 
[ 0.          0.          0.83362573]
best test score       = 
[ 0.          0.          0.88172232]
worst test score      = 
[ 100.          100.            0.78664323]
